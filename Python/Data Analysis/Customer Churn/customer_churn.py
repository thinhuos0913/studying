# -*- coding: utf-8 -*-
"""Customer_Churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kChQ0jY3OjIguP0jw_BMB20s9_mCsVu7
"""

# !pip install xgboost
# !pip install imbalanced-learn
# !pip install category_encoders

# Import library
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns
from sklearn.metrics import plot_confusion_matrix
import category_encoders as ce
from imblearn.over_sampling import SMOTE

customer_data = pd.read_csv("/content/train.csv")

customer_data.head()

"""**1. Exploratory Data Analysis**"""

customer_data.info()

customer_data.isnull().sum()

object_cols = [i for i in customer_data.columns if customer_data[i].dtype =="O"]
print(object_cols)

for col in object_cols:
  customer_data[col].value_counts().plot(kind='bar', figsize=(10,5))
  plt.title(col)
  plt.show()

numerical_cols = [j for j in customer_data.columns if customer_data[j].dtype !="O"]
print(numerical_cols)

for col in numerical_cols:
  customer_data[col].hist()
  plt.title(col)
  plt.show()

for col in numerical_cols:
  customer_data.boxplot(column=[col])
  plt.title(col)
  plt.show()

"""**2. Preprocess Data**"""

data = customer_data.copy()

# Data Encoding
he = ce.HashingEncoder(cols = 'state')
hashed_data = he.fit_transform(data)
hashed_data.head()

dummy_data = pd.get_dummies(hashed_data, drop_first = True)
dummy_data.head()

# Correlation
corr = dummy_data.corr()
corr.style.background_gradient(cmap='coolwarm').set_precision(2)

# Remove high correlation columns
corr_data = dummy_data.drop(columns=["voice_mail_plan_yes","total_day_charge","total_eve_charge","total_night_charge","total_intl_charge"])

"""**3. Training Experiment**"""

# 1. Oversampling with SMOTE, Scale = MinMax, model = Logistic Regression, XGBoost, RandomForest

X = corr_data.drop(["churn_yes"],axis=1)
y = corr_data['churn_yes']

# Split train-test
X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)

# Upsampling = SMOTE
sm = SMOTE(k_neighbors=5)
X_train_resample, y_train_resample = sm.fit_resample(X_train,y_train)

# Scale

scale_columns = ['account_length', 'number_vmail_messages', 'total_day_minutes',
       'total_day_calls', 'total_eve_minutes', 'total_eve_calls',
       'total_night_minutes', 'total_night_calls', 'total_intl_minutes',
       'total_intl_calls', 'number_customer_service_calls']

scaler = MinMaxScaler()
scaler.fit(X_train_resample[scale_columns])
X_train_resample[scale_columns] = scaler.transform(X_train_resample[scale_columns])
X_test[scale_columns] = scaler.transform(X_test[scale_columns])

# Logistic Regression
model = LogisticRegression(C=0.5, max_iter=6700) 
model.fit(X_train_resample, y_train_resample)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))

plot_confusion_matrix(model, X_test, y_test)

# XGBoost
import xgboost as xgb

model = xgb.XGBClassifier(learning_rate = 0.5,n_estimators = 400,random_state=42)
model.fit(X_train_resample, y_train_resample)

y_pred = model.predict(X_test)
# Show result
print(classification_report( y_test, y_pred))
plot_confusion_matrix(model, X_test, y_test)

# RandomForest
from sklearn.ensemble import RandomForestClassifier
from sklearn import ensemble

model = RandomForestClassifier(n_estimators=200, random_state=42)
model.fit(X_train_resample, y_train_resample)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))
plot_confusion_matrix(model, X_test, y_test)

# 2. Oversampling with SMOTE, not scale, model = Logistic Regression, XGBoost, RandomForest
def over_sampling(data):
  X = data.drop(["churn_yes"],axis=1)
  y = data['churn_yes']
  # Split train-test
  X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)
  # Upsampling = SMOTE
  sm = SMOTE(k_neighbors=5)
  X_train_resample, y_train_resample = sm.fit_resample(X_train,y_train)

  return X_train_resample, y_train_resample, X_test, y_test

X_train_resample, y_train_resample, X_test, y_test = over_sampling(corr_data)

X_train_resample.shape

# Logistic Regression
model = LogisticRegression(C=0.01) 
model.fit(X_train_resample, y_train_resample)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))

plot_confusion_matrix(model, X_test, y_test)

# XGBoost
model = xgb.XGBClassifier(learning_rate=0.1,n_estimators=400,random_state=42)
model.fit(X_train_resample,y_train_resample)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))
plot_confusion_matrix(model, X_test, y_test)

# RandomForest
model = RandomForestClassifier(n_estimators = 100, random_state = 42)
model.fit(X_train_resample, y_train_resample)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))
plot_confusion_matrix(model, X_test, y_test)

# 3. No oversampling, scale = MinMax, model = Logistic, XGB, RandomForest
scale_columns = ['account_length', 'number_vmail_messages', 'total_day_minutes',
       'total_day_calls', 'total_eve_minutes', 'total_eve_calls',
       'total_night_minutes', 'total_night_calls', 'total_intl_minutes',
       'total_intl_calls', 'number_customer_service_calls']

def scale_data(data):
  X = data.drop(["churn_yes"],axis=1)
  y = data['churn_yes']
  X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)
  # MinMax Scaler
  scaler = MinMaxScaler()
  scaler.fit(X_train[scale_columns])
  X_train[scale_columns] = scaler.transform(X_train[scale_columns])
  X_test[scale_columns] = scaler.transform(X_test[scale_columns])

  return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = scale_data(corr_data)
X_train.head()

X_train.shape

# Logistic Regression
model = LogisticRegression(C=10., max_iter=6700) 
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))

plot_confusion_matrix(model, X_test, y_test)

# XGBoost
model = xgb.XGBClassifier(learning_rate=0.1,n_estimators=200,random_state=42)
model.fit(X_train,y_train)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))
plot_confusion_matrix(model, X_test, y_test)

# RandomForest
model = RandomForestClassifier(n_estimators = 200, random_state = 42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))
plot_confusion_matrix(model, X_test, y_test)

# 4. No oversampling, no scale, model = Logistic Regression, RandomForest, XGB
X = corr_data.drop(["churn_yes"],axis=1)
y = corr_data['churn_yes']
print(X.shape, y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)
X_train.shape, y_train.shape

# Logistic Regression
model = LogisticRegression(C=10.0, max_iter=6700) 
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))

plot_confusion_matrix(model, X_test, y_test)

# RandomForest
model = RandomForestClassifier(n_estimators = 200, random_state = 42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))
plot_confusion_matrix(model, X_test, y_test)

# XGBoost
model = xgb.XGBClassifier(learning_rate=0.1,n_estimators=200,random_state=42)
model.fit(X_train,y_train)
y_pred = model.predict(X_test)

# Show result
print(classification_report( y_test, y_pred))
plot_confusion_matrix(model, X_test, y_test)

"""**4. Generate .csv file for submitting to Kaggle**"""

test = pd.read_csv("/content/test.csv")
id_submit = test['id']

test.head()

test.drop(columns=['id'], inplace=True)

hashed_test = he.fit_transform(test)
hashed_test.head()

test_dummy =  pd.get_dummies(hashed_test,drop_first=True)
test_dummy_drop_corr = test_dummy.drop(columns=["voice_mail_plan_yes","total_day_charge","total_eve_charge","total_night_charge","total_intl_charge"])

test_dummy_drop_corr.columns

y_pred_submit = model.predict(test_dummy_drop_corr)

y_pred_submit

submit_result = pd.DataFrame({'id': id_submit,'churn': y_pred_submit})
submit_result

submit_result.churn.replace([0,1],['no','yes'],inplace=True)
submit_result

submit_result.to_csv("submit.csv", index=False)